# ğŸ“„ RAG-based Document Question Answering System

A **production-style Retrieval Augmented Generation (RAG)** backend that allows users to upload a PDF document and ask natural language questions grounded strictly in the document content.

This project is designed with **clean architecture, cost efficiency, and interview readiness** in mind.

---

## ğŸš€ Features

* ğŸ“„ PDF ingestion (in-memory)
* âœ‚ï¸ Token-based chunking with overlap
* ğŸ§  OpenAI embeddings (`text-embedding-3-small`)
* ğŸ“¦ Vector storage using QdrantDB
* ğŸ” Semantic retrieval scoped to the latest document
* ğŸ¤– GPT-based grounded answer generation
* ğŸ›¡ï¸ Hallucination-controlled prompts
* ğŸ’¸ Cost-optimized retrieval and generation
* ğŸ³ Fully Dockerized setup

---

## ğŸ—ï¸ Architecture Overview

```
Client
 â””â”€â”€> Django REST API
        â”œâ”€â”€ /api/ingest  (PDF upload)
        â”œâ”€â”€ Chunking + Embeddings
        â”œâ”€â”€ Qdrant Vector Store
        â””â”€â”€ /api/ask     (Question Answering)
               â”œâ”€â”€ Retrieval (Qdrant)
               â””â”€â”€ GPT Answer Generation
```

---

## ğŸ› ï¸ Tech Stack

### Backend

* Python 3.11
* Django
* Django REST Framework

### GenAI

* OpenAI API

  * text-embedding-3-small
  * gpt-4.1-mini

### Vector Database

* Qdrant

### Infrastructure

* Docker & Docker Compose
* PostgreSQL (document metadata)

---

## âš™ï¸ Prerequisites

* Docker
* Docker Compose
* OpenAI API Key

---

## ğŸ” Environment Variables

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_CHAT_MODEL=gpt-4.1-mini
```

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd <project-folder>
```

---

### 2ï¸âƒ£ Start Services Using Docker

```bash
docker-compose up --build
```

This will start:

* Django backend (`http://localhost:8000`)
* PostgreSQL
* Qdrant (`http://localhost:6333/dashboard`)

---

### 3ï¸âƒ£ Apply Database Migrations

```bash
docker exec -it rag_backend bash
python manage.py migrate
```

---

## ğŸ“¤ API Usage

### ğŸ”¹ 1. Ingest PDF

**Endpoint**

```
POST /api/ingest/
```

**Request**

* `multipart/form-data`
* Field: `files` (PDF)

**Response**

```json
{
  "documents": [
    {
      "filename": "resume.pdf",
      "document_id": "uuid",
      "status": "INGESTED",
      "chunk_count": 2
    }
  ]
}
```

---

### ğŸ”¹ 2. Ask Question

**Endpoint**

```
POST /api/ask/
```

**Request Body**

```json
{
  "question": "What technologies does the candidate know?",
  "top_k": 3
}
```

**Response**

```json
{
  "answer": "The candidate has experience with Python, Django, Azure Functions, Docker, and React.",
  "sources": [
    {
      "chunk_index": 0,
      "score": 0.31
    }
  ]
}
```

---

## ğŸ§  Key Design Decisions (Interview Ready)

* **PostgreSQL as source of truth** â€“ tracks document lifecycle and metadata
* **Qdrant only for vector search** â€“ never treated as primary storage
* **Token-based chunking with overlap** â€“ preserves semantic continuity
* **Score-based chunk filtering** â€“ reduces hallucination and cost
* **Grounded prompting** â€“ GPT answers only from retrieved context
* **Low temperature generation** â€“ factual, deterministic answers

---

## ğŸ’° Cost Optimization

* Embeddings are generated **once per document**
* GPT is called **only after retrieval**
* Context size is controlled via `top_k` and similarity score threshold
* Typical cost per question: **~$0.00008**

ğŸ§® TOTAL COST BREAKDOWN (Realistic)

**Action**	                     **Cost**
Upload 1 resume (embedding)	~$0.00001
Ask    1 question	        ~$0.00008
Ask    100 questions	    ~$0.008
Ask    1,000 questions	    ~$0.08
Ask    10,000 questions     ~$0.80

---

## ğŸ§ª Development Notes

* Retrieval is currently scoped to the **latest uploaded document**
* Easy to extend to multi-document search, conversation memory, streaming answers, and frontend UI

---

## ğŸ“Œ Future Enhancements

* Multi-document retrieval
* Conversation memory
* Streaming responses (voice agents)
* React-based frontend chat UI
* User-level rate limiting and quotas

---

## ğŸ‘¨â€ğŸ’» Author
**Mohd Sameer Backend developer at IBM**

Built as a **resume-grade GenAI system** with a focus on clean backend architecture, explainability, cost efficiency, and interview readiness.



